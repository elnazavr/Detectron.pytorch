{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "COCO_PATH = \"data/coco/annotations/instances_train2017.json\"\n",
    "PART_PATH = \"data/coco/parts/annotations/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        tmp = json.load(f)\n",
    "    return tmp\n",
    "\n",
    "def write_to_file(path, info):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(info, f)\n",
    "\n",
    "\n",
    "def img_for_cat(annotations, cats):\n",
    "    images = annotations[\"images\"]\n",
    "    instances = annotations[\"annotations\"]\n",
    "    return list(set([ins[\"image_id\"] for ins in instances if ins[\"category_id\"] in cats]))\n",
    "\n",
    "\n",
    "def get_instances_per_class(instances):\n",
    "    class_number_instances = {}\n",
    "    for instance in instances:\n",
    "        cat_id = instance[\"category_id\"]\n",
    "        if cat_id not in class_number_instances.keys():\n",
    "            class_number_instances[cat_id] = 0\n",
    "        class_number_instances[cat_id] +=1\n",
    "    return class_number_instances\n",
    "\n",
    "def image_ids_by_instances(annotations, instances):\n",
    "    image_ids = [instance[\"image_id\"] for instance in instances]\n",
    "    images = annotations[\"images\"]\n",
    "    return [image for image in images if image[\"id\"] in image_ids]\n",
    "\n",
    "def instances_by_images(annotations, images):\n",
    "    instances = annotations[\"annotations\"]\n",
    "    return [instance for instance in instances if instance[\"image_id\"] in images]\n",
    "\n",
    "def len_intresection(list1, list2):\n",
    "    return len(set(list1).intersection(set(list2)))\n",
    "\n",
    "\n",
    "def random_2_image_assign(imgs1, imgs2, three_set_intresection=set()):\n",
    "    two_set_intresection = list(set(imgs1).intersection(set(imgs2)) - set(three_set_intresection))\n",
    "    N = len(two_set_intresection)\n",
    "    return two_set_intresection[: int(N/2)], two_set_intresection[int(N/2):]\n",
    "\n",
    "\n",
    "def random_image_assign(images):\n",
    "    three_set_intresection = list((set(images[0]).intersection(set(images[1]))).intersection(set(images[2])))\n",
    "    N = len(three_set_intresection)\n",
    "    imgs = [three_set_intresection[: int(N/3)], three_set_intresection[int(N/3): 2*int(N/3)], three_set_intresection[2*int(N/3) :]]\n",
    "    for (i,j) in zip([0,0,1], [1,2,2]):\n",
    "        part1, part2 = random_2_image_assign(images[i], images[j], three_set_intresection)\n",
    "        imgs[i].extend(part1)\n",
    "        imgs[j].extend(part2)\n",
    "    for i in range(3):\n",
    "        xor = set(images[i]) - set(images[(i+1)%3]) - set(images[(i+2)%3])\n",
    "        imgs[i].extend(xor)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def get_instances_for_image_cat_groups(instances, cats_groups, imgs_groups):\n",
    "    annotations_groups = []\n",
    "    instaces_by_image = get_instances_idx_by_images(instances)\n",
    "    for idx in range(len(imgs_groups)):\n",
    "        cats_group = cats_groups[idx]\n",
    "        img_group = imgs_groups[idx]\n",
    "        annotations_group = []\n",
    "        for img in img_group:\n",
    "            instances_idx = instaces_by_image[img]\n",
    "            instances_per_images = [instances[instance_idx] for instance_idx in instances_idx]\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            for instance in instances_per_images:\n",
    "                cat = instance[\"category_id\"]\n",
    "                if cat in cats_group:\n",
    "                    annotations_group.append(instance)\n",
    "        annotations_groups.append(annotations_group)\n",
    "    return annotations_groups\n",
    "\n",
    "\n",
    "def get_instances_idx_by_images(instances):\n",
    "    instaces_by_image = {}\n",
    "    for idx, instance in enumerate(instances):\n",
    "        img_id = instance[\"image_id\"]\n",
    "        if img_id not in instaces_by_image.keys():\n",
    "            instaces_by_image[img_id] = []\n",
    "        instaces_by_image[img_id].append(idx)\n",
    "    return instaces_by_image\n",
    "\n",
    "\n",
    "def get_categories_from_initial_annotations(annotations, cat_ids):\n",
    "    return [cat_info for cat_info in annotations[\"categories\"] if cat_info[\"id\"] in cat_ids]\n",
    "\n",
    "\n",
    "def create_group_dataset(annotations, instances_group, images_group_ids, cats_group_ids):\n",
    "    images = annotations[\"images\"]\n",
    "    images_group = [image for image in images if image[\"id\"] in images_group_ids]\n",
    "    categories_group = get_categories_from_initial_annotations(annotations, cats_group_ids)\n",
    "    return create_dataset(instances_group, images_group, categories_group)\n",
    "\n",
    "def create_dataset(instances_group, images_group, categories_group):\n",
    "    annotations_group = {}\n",
    "    annotations_group[\"annotations\"] = instances_group\n",
    "    annotations_group[\"images\"] = images_group\n",
    "    annotations_group[\"categories\"] = categories_group\n",
    "    return annotations_group\n",
    "\n",
    "def get_cats_group(instances):\n",
    "    instances_per_class = get_instances_per_class(instances)\n",
    "    instances_per_class_sorted = list(reversed(sorted(instances_per_class.items(), key = lambda x: x[1])))\n",
    "    cat_group1 = [instances_per_class_sorted[i][0] for i in range(2, len(instances_per_class_sorted), 2)]\n",
    "    cat_group2 = [instances_per_class_sorted[i][0] for i in range(1, len(instances_per_class_sorted), 2)]\n",
    "    cat_group3 = [instances_per_class_sorted[0][0]]\n",
    "    cats_groups = [cat_group1, cat_group2, cat_group3]\n",
    "    return cats_groups\n",
    "\n",
    "\n",
    "def dataset_from_cats(annotations, cats_groups, suffix=\"_train\"):\n",
    "    instances = annotations[\"annotations\"]\n",
    "    images = [img_for_cat(annotations, [idx for idx in group]) for group in cats_groups]\n",
    "    images_groups = random_image_assign(images)\n",
    "    instances_groups_train= get_instances_for_image_cat_groups(instances, cats_groups, images_groups)\n",
    "    \n",
    "    for idx in range(len(images)):\n",
    "        annotations_group = create_group_dataset(annotations, instances_groups_train[idx], images_groups[idx], cats_groups[idx])\n",
    "        #write_to_file( os.path.join(PART_PATH, str(idx)+suffix+\".json\"), annotations_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = read_file(COCO_PATH)\n",
    "instances = annotations[\"annotations\"]\n",
    "cats_groups = get_cats_group(instances)\n",
    "dataset_from_cats(annotations, cats_groups, suffix=\"_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(group) for group in cats_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_PATH_VAL = \"data/coco/annotations/instances_val2017.json\"\n",
    "annotations_val = read_file(COCO_PATH_VAL)\n",
    "dataset_from_cats(annotations_val, cats_groups, suffix = \"_val\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = read_file(COCO_PATH)\n",
    "len(annotations[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In 1,2,3 group theare are \", [len(img) for img in images ], \"images\")\n",
    "print(\"In 1,2,3 group theare are \", [len(group) for group in cats_groups], \"cats\")\n",
    "print(\"Image intresection of (0,1), (0,2), (1,3)\", [len_intresection(images[x], images[y]) for (x,y) in zip([0,0,1], [1,2,2])]) \n",
    "print(\"Image inresection of (0,1,2)\", len((set(images[0]).intersection(set(images[1]))).intersection(set(images[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final annnoations of files. Images \",  list(map(lambda x: len(x), images_groups)))\n",
    "print(\"Final annnoations of files train. Instances \",  list(map(lambda x: len(x), instances_groups_train)))\n",
    "print(\"Final annnoations of files val. Instances \",  list(map(lambda x: len(x), instances_groups_vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of groups instances/ total initial number\", sum(list(map(lambda x: len(x), instances_groups)))/ len(instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"0.json\", \"0_train.json\", \"0_val.json\"]\n",
    "file = files[2]\n",
    "annotations = {}\n",
    "with open(os.path.join(PART_PATH, file), \"r\") as f:\n",
    "        annotations[file] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations[files[2]][\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(annotations[i][\"categories\"]) for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(PART_PATH)\n",
    "for file in files:\n",
    "    with open(os.path.join(PART_PATH, file), \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    instances = annotations[\"annotations\"]\n",
    "    images = annotations[\"images\"]\n",
    "    random.shuffle(images)\n",
    "    N = len(images)\n",
    "    train_img, val_img = images[:int(0.8*N)], images[int(0.8*N):]\n",
    "    train_inst, val_inst = instances_by_images(annotations, train_inst), instances_by_images(annotations, val_inst)\n",
    "    train_dataset, val_dataset = create_dataset(train_inst, train_img, annotations[\"categories\"]), create_dataset(train_val, train_val, annotations[\"categories\"])\n",
    "    base_filename = os.path.join(PART_PATH, file).split(\".json\")[0]\n",
    "    write_to_file(base_filename+\"+_val.json\", val_dataset)\n",
    "    write_to_file(base_filename+\"+_train.json\", train_dataset)\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statictis of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"0_train.json\", \"_train.json\", \"2_val.json\"]\n",
    "annotations = {}\n",
    "with open(os.path.join(PART_PATH, file), \"r\") as f:\n",
    "        annotations[file] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Val based on Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_PATH = \"../data/coco/annotations/instances_val2017.json\"\n",
    "PART_PATH = \"../data/coco/intresected_parts/annotations/\"\n",
    "val = read_file(COCO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../data/coco/annotations/instances_val2017.json/0_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ac2717ea9edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"0_train.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_train.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2_val.json\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOCO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"categories\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mann_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mann\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"annotations\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-97ca7b8e59c5>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../data/coco/annotations/instances_val2017.json/0_train.json'"
     ]
    }
   ],
   "source": [
    "files = [\"0_train.json\", \"_train.json\", \"2_val.json\"]\n",
    "for idx, file in ennumerate(files):\n",
    "    annotations = read_file(os.path.join(PART_PATH, file))\n",
    "    cats = annotations[\"categories\"]\n",
    "    ann_parts = [ann for ann in val[\"annotations\"] if ann[\"category_id\"] in cats]\n",
    "    write_to_file(os.path.join(PART_PATH, \"coco\"+str(idx)+\"_val.json\"), \n",
    "                  {\"images\": val[\"images\"], \n",
    "                   \"annotations\": ann_parts,\n",
    "                  \"categories\": cats})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
