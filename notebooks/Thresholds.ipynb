{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from tools.utils import draw_bbboxes\n",
    "from pycocotools.coco import COCO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home.nfs/babayeln/doc\n",
      "loading annotations into memory...\n",
      "Done (t=17.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "OUTPUT_PATH=\"images/threshold_study/final_feature_db_on_train.npy\"\n",
    "feautre_db = np.load(OUTPUT_PATH)\n",
    "coco = COCO(\"/home.nfs/babayeln/thesis/mask-rcnn.pytorch/data/coco/annotations/instances_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_cat_to_continous_cat = {v: i+1 for i,v in enumerate(coco.cats)}\n",
    "continious_cat_to_coco = {v:k for k,v in coco_cat_to_continous_cat.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threhold_for_each_class(index, db, classes,  k_neighbours=10):\n",
    "    print(\"Doing search\")\n",
    "    distance, indecies = index.search(db, k_neighbours)\n",
    "    print(\"Finishing search\")\n",
    "    classes_idx = classes[indecies]\n",
    "    distance_class = {}\n",
    "    counts = {}\n",
    "    for idx, neighbours in enumerate(classes_idx):\n",
    "        myself = int(classes[idx])\n",
    "        not_class_neighbours = np.where(neighbours!=myself)[0]\n",
    "        if len(not_class_neighbours) == 0:\n",
    "            not_class_neighbours = [k_neighbours-1]\n",
    "        first_not_class_neighbours = not_class_neighbours[0]\n",
    "        #if first_not_class_neighbours==0:\n",
    "        #    import ipdb; ipdb.set_trace()\n",
    "        if myself not in counts.keys():\n",
    "            counts[myself] = []\n",
    "            distance_class[myself] = []\n",
    "        counts[myself].append(first_not_class_neighbours)\n",
    "        distance_class[myself].append(distance[idx, first_not_class_neighbours])\n",
    "        \n",
    "    average_distance_class = {}\n",
    "    for class_idx in distance_class.keys():\n",
    "        average_distance_class[class_idx] = np.median(distance_class[class_idx])\n",
    "    return average_distance_class, counts, classes_idx, distance, indecies\n",
    "\n",
    "\n",
    "def xyxy_to_xywh(xyxy):\n",
    "    \"\"\"Convert [x1 y1 x2 y2] box format to [x1 y1 w h] format.\"\"\"\n",
    "    if isinstance(xyxy, (list, tuple)):\n",
    "        # Single box given as a list of coordinates\n",
    "        assert len(xyxy) == 4\n",
    "        x1, y1 = xyxy[0], xyxy[1]\n",
    "        w = xyxy[2] - x1 + 1\n",
    "        h = xyxy[3] - y1 + 1\n",
    "        return (x1, y1, w, h)\n",
    "    elif isinstance(xyxy, np.ndarray):\n",
    "        # Multiple boxes given as a 2D ndarray\n",
    "        return np.hstack((xyxy[:, 0:2], xyxy[:, 2:4] - xyxy[:, 0:2] + 1))\n",
    "    else:\n",
    "        raise TypeError('Argument xyxy must be a list, tuple, or numpy array.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_db(database, M=128, nbits=8, nlist=316, nprobe=32):\\n    quantizer = faiss.IndexFlatL2(1024)\\n    #index = faiss.IndexIVFPQ(quantizer, 1024, nlist, M, nbits)\\n    index = faiss.IndexIVFFlat(quantizer, 1024, nlist)\\n    N = int(len(database))\\n    samples = database[np.random.permutation(np.arange(N))[:N]]\\n    index.train(samples)\\n    index.add(database)\\n    return index'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_db(db):\n",
    "    dimension = 1024\n",
    "    db = db.astype('float32')\n",
    "    faiss_db = faiss.IndexFlatL2(dimension)\n",
    "    faiss_db.add(db)\n",
    "    return faiss_db\n",
    "\"\"\"\n",
    "def create_db(database, M=128, nbits=8, nlist=316, nprobe=32):\n",
    "    quantizer = faiss.IndexFlatL2(1024)\n",
    "    #index = faiss.IndexIVFPQ(quantizer, 1024, nlist, M, nbits)\n",
    "    index = faiss.IndexIVFFlat(quantizer, 1024, nlist)\n",
    "    N = int(len(database))\n",
    "    samples = database[np.random.permutation(np.arange(N))[:N]]\n",
    "    index.train(samples)\n",
    "    index.add(database)\n",
    "    return index\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_db = create_db(np.array(feautre_db[:, 7:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(feautre_db[:, 2])\n",
    "features = np.array(feautre_db[:, 7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing search\n"
     ]
    }
   ],
   "source": [
    "#classes_idx, indecies,  distance = find_threhold_for_each_class(faiss_db, features, classes,  k_neighbours=10)\n",
    "\n",
    "%time average_distance_class, counts, classes_idx, distances, indecies = find_threhold_for_each_class(faiss_db, features, classes,  k_neighbours=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"images/threshold_study/nearest_neighbour_5.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"average_distance_class\" : average_distance_class,\n",
    "        \"counts\" : counts,\n",
    "        \"classes_idx\": classes_idx,\n",
    "        \"distances\": distances,\n",
    "        \"indecies\" : indecies\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0, 819276, 135478, 652556, 360902],\n",
       "       [     1, 266078,      3, 684495, 485016],\n",
       "       [     2,  31170, 147105,  59081, 134175],\n",
       "       ...,\n",
       "       [859950, 119011, 387249, 209479, 713814],\n",
       "       [859951,  61269, 390625, 512074, 454202],\n",
       "       [859952, 541633,  81518, 540341, 118740]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indecies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chossing different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_top_x_not_weighted(x):\n",
    "    matrix = np.zeros(shape = (81, 81))\n",
    "    weights = [1, 1, 1, 1, 1]\n",
    "    for idx, neighbours in enumerate(classes_idx):\n",
    "        neighbours = neighbours[:x+1]\n",
    "        for position, neighbour in enumerate(neighbours[1:]):\n",
    "            #if neighbour!=classes[idx]:\n",
    "            matrix[int(classes[idx]), int(neighbour)] += weights[position] \n",
    "    for idx in range(matrix.shape[0]):\n",
    "        matrix[idx] = np.round(matrix[idx]/ np.sum(matrix[idx], axis=0),4)\n",
    "    return matrix\n",
    "\n",
    "def get_df(matrix):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(matrix)\n",
    "    names = [\"background\"] + [coco.cats[coco_cat][\"name\"] for (cat, coco_cat) in continious_cat_to_coco.items()]\n",
    "    df.set_axis(names, axis=0)\n",
    "    df.set_axis(names, axis=1)\n",
    "    df.style.background_gradient()\n",
    "    return df\n",
    "\n",
    "def draw_df(df, name, figsize=(20, 20), ann=False ):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    pal = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "    sns_plot = sns.heatmap(ax = ax, data=df, cmap=pal, annot=ann)\n",
    "    sns_plot.get_figure().savefig(\"nn_review/\" + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_5 = get_top_x_not_weighted(5)\n",
    "d_5 = get_df(m_5)\n",
    "draw_df(d, \"top5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_top_x_not_weighted(1)\n",
    "d = get_df(m)\n",
    "draw_df(d, \"top1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_5[1], m[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"nn_review/nn_to_wrong_classes_5.pkl\")\n",
    "df.style.background_gradient().to_excel(\"nn_review/nn_to_wrong_classes_5.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chosing yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros(shape = (81,4))\n",
    "for idx, neighbours in enumerate(classes_idx):\n",
    "    for position, neighbour in enumerate(neighbours[1:]):\n",
    "        if neighbour==classes[idx]:\n",
    "            matrix[int(neighbour)][position]+=1\n",
    "for idx in range(matrix.shape[0]):\n",
    "    matrix[idx] = np.round(matrix[idx]/ np.sum(matrix[idx]),3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(matrix[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(matrix)\n",
    "names = [\"background\"] + [coco.cats[coco_cat][\"name\"] for (cat, coco_cat) in continious_cat_to_coco.items()]\n",
    "df.set_axis(names, axis=0)\n",
    "df.style.background_gradient()\n",
    "draw_df(df, \"same_class_%\", figsize=(5,20), ann=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"nn_review/class_place_apperance.pkl\")\n",
    "df.style.background_gradient().to_excel(\"nn_review/class_place_apperance.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [coco.cats[continious_cat_to_coco[x]][\"name\"] for x in average_distance_class.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize=(20, 20))\n",
    "\n",
    "#plt.bar(average_distance_class.keys(), average_distance_class.values())\n",
    "dictionary = {\"class\": [], \"mean_distance\": []}\n",
    "for key,value in average_distance_class.items():\n",
    "    dictionary[\"class\"].append(coco.cats[continious_cat_to_coco[key]][\"name\"])\n",
    "    dictionary[\"mean_distance\"].append(value)\n",
    "df = pd.DataFrame(dictionary)\n",
    "df = df.sort_values('mean_distance')\n",
    "ax = df.plot.barh(x='class', y='mean_distance', rot=0, figsize=(20,20))\n",
    "fig = ax.get_figure()\n",
    "\n",
    "fig.savefig(\"nn_review/median_distance.png\")\n",
    "\n",
    "#x = list(range(81))\n",
    "#my_xticks = [coco.cats[coco_cat][\"name\"] for (cat, coco_cat) in continious_cat_to_coco.items()]\n",
    "#plt.xticks(x, my_xticks, rotation=45)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict= {}\n",
    "for idx in range(len(distances)):\n",
    "    me = int(classes[idx])\n",
    "    for distance,other in zip(distances[idx], classes_idx[idx]):\n",
    "        key = (me, int(other))\n",
    "        if key not in tmp_dict.keys():\n",
    "            tmp_dict[key] = []\n",
    "        if distance<0:\n",
    "            distance=0\n",
    "        tmp_dict[key].append(distance)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((81, 81))\n",
    "for (me, other) in tmp_dict.keys():\n",
    "    matrix[me][other] = np.median(tmp_dict[(me, other)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(matrix)\n",
    "names = [\"background\"] + [coco.cats[coco_cat][\"name\"] for (cat, coco_cat) in continious_cat_to_coco.items()]\n",
    "df.set_axis(names, axis=0)\n",
    "df.set_axis(names, axis=1)\n",
    "df.style.background_gradient()\n",
    "draw_df(df, name=\"median_distance\", ann=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"nn_review/mean_distance_to_different_classes.pkl\")\n",
    "df.style.background_gradient().to_excel(\"nn_review/mean_distance_to_different_classes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_gradient_id_for_background(faiss_db, feautre_db, looked_features, thresholds, k_neighbours ):\n",
    "    distance, indecies = faiss_db.search(looked_features, k_neighbours)\n",
    "    #feautre_db[indecies].shape -> number of features, k_neighbours, 1031 dimension vector\n",
    "    classes = feautre_db[indecies][:, :, 2]\n",
    "    max_classes = [np.argmax(np.bincount(sample.astype(\"int64\"))) for sample in classes]\n",
    "    class_thresholds = thresholds[max_classes]\n",
    "    passed_thresholds = np.where( np.min(distance, axis=1) < class_thresholds)[0]\n",
    "    background_gradient_idx = np.array(set(range(len(looked_features))) - set(passed_thresholds))\n",
    "    return background_gradient_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_gradient_idx = choose_gradient_id_for_background(faiss_db, feautre_db, looked_features, thresholds, k_neighbours )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "background_gradient_idx = choose_gradient_id_for_background(faiss_db, feautre_db, looked_features, thresholds, k_neighbours )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
